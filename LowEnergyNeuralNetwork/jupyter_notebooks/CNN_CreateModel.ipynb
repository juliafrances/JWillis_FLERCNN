{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ONLY RUN ON PRE-TRANSFORMED FILES!!!!!!!!!! ###\n",
    "\n",
    "#########################\n",
    "# Version of DNN using Mirco Config\n",
    "# Set to take in Robust tranformed file\n",
    "# Runs net and plots\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import h5py\n",
    "import time\n",
    "import os, sys\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables (USE TRANSFORMED TRAINING FILE ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE VARIABLES HERE ###\n",
    "\n",
    "## RUN TrasnformFiles_OutputHDF5 first !!!! ### \n",
    "input_file = '/home/jovyan/Level5p_IC86.2013_genie_nue.012640.300.transformed.hdf5' #'Level5_IC86.2013_genie_nue.012640.100.cascade.lt60_vertexDC.transformed.hdf5'\n",
    "filename = 'nue_cascade_test_play' #Output model name\n",
    "num_epochs = 5\n",
    "dropout = 0.2\n",
    "save = True\n",
    "save_folder_name = filename + \"/\"\n",
    "old_model_name = \"old_model.hdf5\" #If you want to read in an older model before starting training. NOTE: CURRENTLY COMMENTED OUT!\n",
    "\n",
    "DC_drop_value = dropout\n",
    "IC_drop_value = dropout\n",
    "connected_drop_value = dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT FILE #\n",
    "f = h5py.File(input_file, 'r')\n",
    "Y_train = f['Y_train'][:]\n",
    "Y_test = f['Y_test'][:]\n",
    "X_train_DC = f['X_train_DC'][:]\n",
    "X_test_DC = f['X_test_DC'][:]\n",
    "X_train_IC = f['X_train_IC'][:]\n",
    "X_test_IC = f['X_test_IC'][:]\n",
    "f.close()\n",
    "del f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 258677, Testing set: 28742\n"
     ]
    }
   ],
   "source": [
    "# Y train has 11 variables, want to train on energy only right now\n",
    "# Labels: [ nu energy, nu zenith, nu azimuth, nu time, nu x, nu y, nu z, track length (0 for cascade), isTrack (track = 1, cascasde = 0), \n",
    "#         flavor, type (anti = 1), isCC (CC=1, NC = 0)]\n",
    "\n",
    "Y_train = Y_train[:,0] # ENERGY ONLY\n",
    "#Y_test = Y_test[:,0] # ENERGY ONLY\n",
    "\n",
    "# Return features and labels, to be used for network\n",
    "num_features_DC = X_train_DC.shape[-1]\n",
    "num_features_IC = X_train_IC.shape[-1]\n",
    "num_labels = 1 #Y_train.shape[-1] ## NEED TO CHANGE MANUALLY!\n",
    "print(\"Training set: %i, Testing set: %i\"%(len(Y_train),len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data DC (258677, 8, 60, 5)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train Data IC (258677, 7, 60, 5)\n"
     ]
    }
   ],
   "source": [
    "### BUILD THE NETWORK ###\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# DEEP CORE #\n",
    "print(\"Train Data DC\", X_train_DC.shape)\n",
    "strings = X_train_DC.shape[1]\n",
    "dom_per_string = X_train_DC.shape[2]\n",
    "dom_variables = X_train_DC.shape[3]\n",
    "\n",
    "# Conv DC + batch normalization, later dropout and maxpooling\n",
    "input_DC = Input(shape=(strings, dom_per_string, dom_variables))\n",
    "\n",
    "conv1_DC = Conv2D(100,kernel_size=(strings,5),padding='same',activation='tanh')(input_DC) #tanh\n",
    "batch1_DC = BatchNormalization()(conv1_DC)\n",
    "pool1_DC = MaxPooling2D(pool_size=(1,2))(batch1_DC)\n",
    "drop1_DC = Dropout(DC_drop_value)(pool1_DC)\n",
    "\n",
    "conv2_DC = Conv2D(100,kernel_size=(strings,7),padding='same',activation='relu')(drop1_DC) #relu\n",
    "batch2_DC = BatchNormalization()(conv2_DC)\n",
    "drop2_DC = Dropout(DC_drop_value)(batch2_DC)\n",
    "\n",
    "conv3_DC = Conv2D(100,kernel_size=(strings,7),padding='same',activation='relu')(drop2_DC)\n",
    "batch3_DC = BatchNormalization()(conv3_DC)\n",
    "drop3_DC = Dropout(DC_drop_value)(batch3_DC)\n",
    "\n",
    "conv4_DC = Conv2D(100,kernel_size=(strings,3),padding='valid',activation='relu')(drop3_DC)\n",
    "batch4_DC = BatchNormalization()(conv4_DC)\n",
    "pool4_DC = MaxPooling2D(pool_size=(1,2))(batch4_DC)\n",
    "drop4_DC = Dropout(DC_drop_value)(pool4_DC)\n",
    "\n",
    "conv5_DC = Conv2D(100,kernel_size=(1,7),padding='same',activation='relu')(drop4_DC)\n",
    "batch5_DC = BatchNormalization()(conv5_DC)\n",
    "drop5_DC = Dropout(DC_drop_value)(batch5_DC)\n",
    "\n",
    "conv6_DC = Conv2D(100,kernel_size=(1,7),padding='same',activation='relu')(drop5_DC)\n",
    "batch6_DC = BatchNormalization()(conv6_DC)\n",
    "drop6_DC = Dropout(DC_drop_value)(batch6_DC)\n",
    "\n",
    "conv7_DC = Conv2D(100,kernel_size=(1,1),padding='same',activation='relu')(drop6_DC)\n",
    "batch7_DC = BatchNormalization()(conv7_DC)\n",
    "drop7_DC = Dropout(DC_drop_value)(batch7_DC)\n",
    "\n",
    "conv8_DC = Conv2D(100,kernel_size=(1,1),padding='same',activation='relu')(drop7_DC)\n",
    "batch8_DC = BatchNormalization()(conv8_DC)\n",
    "drop8_DC = Dropout(DC_drop_value)(batch8_DC)\n",
    "\n",
    "flat_DC = Flatten()(drop8_DC)\n",
    "\n",
    "# ICECUBE NEAR DEEPCORE #\n",
    "print(\"Train Data IC\", X_train_IC.shape)\n",
    "strings_IC = X_train_IC.shape[1]\n",
    "dom_per_string_IC = X_train_IC.shape[2]\n",
    "dom_variables_IC = X_train_IC.shape[3]\n",
    "\n",
    "# Conv DC + batch normalization, later dropout and maxpooling\n",
    "input_IC = Input(shape=(strings_IC, dom_per_string_IC, dom_variables_IC))\n",
    "\n",
    "conv1_IC = Conv2D(100,kernel_size=(strings_IC,5),padding='same',activation='tanh')(input_IC)\n",
    "batch1_IC = BatchNormalization()(conv1_IC)\n",
    "pool1_IC = MaxPooling2D(pool_size=(1,2))(batch1_IC)\n",
    "drop1_IC = Dropout(IC_drop_value)(pool1_IC)\n",
    "\n",
    "conv2_IC = Conv2D(100,kernel_size=(strings_IC,7),padding='same',activation='relu')(drop1_IC)\n",
    "batch2_IC = BatchNormalization()(conv2_IC)\n",
    "drop2_IC = Dropout(IC_drop_value)(batch2_IC)\n",
    "\n",
    "conv3_IC = Conv2D(100,kernel_size=(strings_IC,7),padding='same',activation='relu')(drop2_IC)\n",
    "batch3_IC = BatchNormalization()(conv3_IC)\n",
    "drop3_IC = Dropout(IC_drop_value)(batch3_IC)\n",
    "\n",
    "conv4_IC = Conv2D(100,kernel_size=(strings_IC,3),padding='valid',activation='relu')(drop3_IC)\n",
    "batch4_IC = BatchNormalization()(conv4_IC)\n",
    "pool4_IC = MaxPooling2D(pool_size=(1,2))(batch4_IC)\n",
    "drop4_IC = Dropout(IC_drop_value)(pool4_IC)\n",
    "\n",
    "conv5_IC = Conv2D(100,kernel_size=(1,7),padding='same',activation='relu')(drop4_IC)\n",
    "batch5_IC = BatchNormalization()(conv5_IC)\n",
    "drop5_IC = Dropout(IC_drop_value)(batch5_IC)\n",
    "\n",
    "conv6_IC = Conv2D(100,kernel_size=(1,7),padding='same',activation='relu')(drop5_IC)\n",
    "batch6_IC = BatchNormalization()(conv6_IC)\n",
    "drop6_IC = Dropout(IC_drop_value)(batch6_IC)\n",
    "\n",
    "conv7_IC = Conv2D(100,kernel_size=(1,1),padding='same',activation='relu')(drop6_IC)\n",
    "batch7_IC = BatchNormalization()(conv7_IC)\n",
    "drop7_IC = Dropout(IC_drop_value)(batch7_IC)\n",
    "\n",
    "conv8_IC = Conv2D(100,kernel_size=(1,1),padding='same',activation='relu')(drop7_IC)\n",
    "batch8_IC = BatchNormalization()(conv8_IC)\n",
    "drop8_IC = Dropout(IC_drop_value)(batch8_IC)\n",
    "\n",
    "flat_IC = Flatten()(drop8_IC)\n",
    "\n",
    "# PUT TOGETHER #\n",
    "concatted = concatenate([flat_DC, flat_IC])\n",
    "\n",
    "full1 = Dense(300,activation='relu')(concatted)\n",
    "batch1_full = BatchNormalization()(full1)\n",
    "dropf = Dropout(connected_drop_value)(batch1_full)\n",
    "\n",
    "output = Dense(num_labels,activation='linear')(dropf)\n",
    "#batch2_full = BatchNormalization()(output)\n",
    "#lambda_layer = Lambda(lambda x: (x*20.)/1.+3)(output)\n",
    "lambda_layer = Lambda(lambda x: (x*335)/1.)(output)\n",
    "model_DC = Model(inputs=[input_DC,input_IC],outputs=lambda_layer)\n",
    "\n",
    "#print(model_DC.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile ##\n",
    "model_DC.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=1.e-3), #0.00001\n",
    "              metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to load a model (already trained) in to add to\n",
    "#model_DC.load_weights(old_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194007 samples, validate on 64670 samples\n",
      "Epoch 1/5\n",
      "194007/194007 [==============================] - 271s 1ms/step - loss: 82.9696 - mean_squared_error: 82.9696 - val_loss: 68.2617 - val_mean_squared_error: 68.2617\n",
      "Epoch 2/5\n",
      "194007/194007 [==============================] - 258s 1ms/step - loss: 73.4027 - mean_squared_error: 73.4027 - val_loss: 69.4311 - val_mean_squared_error: 69.4311\n",
      "Epoch 3/5\n",
      "194007/194007 [==============================] - 260s 1ms/step - loss: 67.7466 - mean_squared_error: 67.7466 - val_loss: 64.8973 - val_mean_squared_error: 64.8973\n",
      "Epoch 4/5\n",
      "194007/194007 [==============================] - 260s 1ms/step - loss: 64.1719 - mean_squared_error: 64.1719 - val_loss: 63.9818 - val_mean_squared_error: 63.9818\n",
      "Epoch 5/5\n",
      "194007/194007 [==============================] - 261s 1ms/step - loss: 60.4141 - mean_squared_error: 60.4141 - val_loss: 57.5427 - val_mean_squared_error: 57.5427\n",
      "This took me 22.060043 minutes\n"
     ]
    }
   ],
   "source": [
    "## Run neural network and record time ##\n",
    "t0 = time.time()\n",
    "network_history = model_DC.fit([X_train_DC, X_train_IC], Y_train,\n",
    "                            batch_size=256,\n",
    "                            validation_split=0.25,\n",
    "                            epochs=num_epochs,\n",
    "                            callbacks = [EarlyStopping(patience=6), ModelCheckpoint('current_model_while_running.hdf5')],\n",
    "                            verbose=1)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"This took me %f minutes\"%((t1-t0)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28742/28742 [==============================] - 12s 409us/step\n",
      "final score on test data: loss: 58.2880 / accuracy: 58.2880\n",
      "dict_keys(['val_loss', 'val_mean_squared_error', 'loss', 'mean_squared_error'])\n",
      "[58.28800062562203, 58.28800062562203]\n"
     ]
    }
   ],
   "source": [
    "score = model_DC.evaluate([X_test_DC,X_test_IC], Y_test[:,0], batch_size=256)\n",
    "print(\"final score on test data: loss: {:.4f} / accuracy: {:.4f}\".format(score[0], score[1]))\n",
    "print(network_history.history.keys())\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE FOR FUTURE USE! ##\n",
    "model_DC.save(\"/mnt/scratch/micall12/training_files/%s_model.hdf5\"%filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set - Predict Reconstructed Energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "Y_test_predicted = model_DC.predict([X_test_DC,X_test_IC])\n",
    "\n",
    "Y_test_all_labels = numpy.copy(Y_test)\n",
    "Y_test_predicted_energy = numpy.reshape(Y_test_predicted, Y_test_predicted.shape[0])\n",
    "Y_test_energy = numpy.reshape(Y_test[:,0], Y_test.shape[0]) #Only compare ENERGY, change Y_test[:,i] \n",
    "\n",
    "if save==True:\n",
    "    if os.path.isdir(save_folder_name) != True:\n",
    "        os.mkdir(save_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(network_history,save=False,savefolder=None):\n",
    "    \"\"\"\n",
    "    Plot history of neural network's loss vs. epoch\n",
    "    Recieves:\n",
    "        network_history = array, saved metrics from neural network training\n",
    "        save = optional, bool to save plot\n",
    "        savefolder = optional, output folder to save to, if not in current dir\n",
    "    Returns:\n",
    "        one plot, saved to files\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    #plt.yscale('log')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    if save == True:\n",
    "        plt.savefig(\"%sloss_vs_epochs.png\"%savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions_CCNC(truth_all_labels,truth,reco,save=False,savefolder=None):\n",
    "    \"\"\"\n",
    "    Plot testing set distribution, with CC and NC distinguished\n",
    "    Recieves:\n",
    "        truth_all_labels = array, Y_test truth labels that have ALL values in them (need CC vs NC info)\n",
    "        truth = array, Y_test truth labels\n",
    "        reco = array, neural network prediction output\n",
    "        save = optional, bool to save plot\n",
    "        savefolder = optional, output folder to save to, if not in current dir\n",
    "    Returns:\n",
    "        1D histogram of energy distribution with sepearated CC and NC distinction\n",
    "    \"\"\"\n",
    "    CC_mask = truth_all_labels[:,11] ==1\n",
    "    NC_mask = truth_all_labels[:,11] ==0\n",
    "    num_CC = sum(CC_mask)\n",
    "    num_NC = sum(NC_mask)\n",
    "    print(\"CC events: %i, NC events: %i, Percent NC: %.2f\"%(num_CC,num_NC,float(num_NC/(num_CC+num_NC))*100.))\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(\"True Energy Distribution\")\n",
    "    plt.hist(truth[CC_mask], bins=100,color='b',alpha=0.5,label=\"CC\");\n",
    "    plt.hist(truth[NC_mask], bins=100,color='g',alpha=0.5,label=\"NC\");\n",
    "    plt.xlabel(\"Energy (GeV)\")\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(\"%sTrueEnergyDistribution_CCNC.png\"%savefolder)\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(\"NN Energy Distribution\")\n",
    "    plt.hist(reco[CC_mask], bins=100,color='b', alpha=0.5, label=\"CC\");\n",
    "    plt.hist(reco[NC_mask], bins=100,color='g', alpha=0.5, label=\"NC\");\n",
    "    plt.xlabel(\"Energy (GeV)\")\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(\"%sNNEnergyDistribution_CCNC.png\"%savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_resolution_CCNC(truth_all_labels,truth,reco,save=False,savefolder=None):\n",
    "    \"\"\"\n",
    "    Plot testing set resolution of reconstruction - truth, with CC and NC distinguished\n",
    "    Recieves:\n",
    "        truth_all_labels = array, Y_test truth labels that have ALL values in them (need CC vs NC info)\n",
    "        truth = array, Y_test truth labels\n",
    "        reco = array, neural network prediction output\n",
    "        save = optional, bool to save plot\n",
    "        savefolder = optional, output folder to save to, if not in current dir\n",
    "    Returns:\n",
    "        1D histogram of reco - true with sepearated CC and NC distinction\n",
    "    \"\"\"\n",
    "    CC_mask = truth_all_labels[:,11] ==1\n",
    "    NC_mask = truth_all_labels[:,11] ==0\n",
    "    num_CC = sum(CC_mask)\n",
    "    num_NC = sum(NC_mask)\n",
    "    print(\"CC events: %i, NC events: %i, Percent NC: %.2f\"%(num_CC,num_NC,float(num_NC/(num_CC+num_NC))*100.))\n",
    "\n",
    "    resolution = reco - truth\n",
    "    resolution_fraction = (reco - truth)/truth\n",
    "    resolution = numpy.array(resolution)\n",
    "    resolution_fraction  = numpy.array(resolution_fraction)\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(\"Energy Resolution\")\n",
    "    plt.hist(resolution[CC_mask], bins=50,color='b', alpha=0.5, label=\"CC\");\n",
    "    plt.hist(resolution[NC_mask], bins=50,color='g', alpha=0.5, label=\"NC\");\n",
    "    plt.xlabel(\"NN reconstruction - truth (GeV)\")\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(\"%sEnergyResolution_CCNC.png\"%savefolder)\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(\"Fractional Energy Resolution\")\n",
    "    plt.hist(resolution_fraction[CC_mask], bins=50,color='b', alpha=0.5, label=\"CC\");\n",
    "    plt.hist(resolution_fraction[NC_mask], bins=50,color='g', alpha=0.5, label=\"NC\");\n",
    "    plt.xlabel(\"(NN reconstruction - truth) / truth\")\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(\"%sEnergyResolutionFrac_CCNC.png\"%savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_prediction(truth, nn_reco, \\\n",
    "                        save=False,savefolder=None,syst_set=\"\",\\\n",
    "                        use_fraction=False,bins=60,\\\n",
    "                        minenergy=0.,maxenergy=60.):\n",
    "    \"\"\"\n",
    "    Plot testing set reconstruction vs truth\n",
    "    Recieves:\n",
    "        truth = array, Y_test truth\n",
    "        nn_reco = array, neural network prediction output\n",
    "        save = optional, bool to save plot\n",
    "        savefolder = optional, output folder to save to, if not in current dir\n",
    "    Returns:\n",
    "        2D plot of True vs Reco\n",
    "    \"\"\"\n",
    "    if not use_fraction:\n",
    "        plt.figure(figsize=(10,7))\n",
    "        cts,xbin,ybin,img = plt.hist2d(truth, nn_reco, bins=bins)\n",
    "        plt.plot([minenergy,maxenergy],[minenergy,maxenergy],'k:')\n",
    "        plt.xlim(minenergy,maxenergy)\n",
    "        plt.ylim(minenergy,maxenergy)\n",
    "        plt.xlabel(\"True Neutrino Energy (GeV)\")\n",
    "        plt.ylabel(\"NN Reconstruction Energy (GeV)\")\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.set_ylabel('counts', rotation=90)\n",
    "        plt.set_cmap('viridis_r')\n",
    "        plt.title(\"Reconstruction (from NN) vs Truth for Energy\")\n",
    "        if save == True:\n",
    "            plt.savefig(\"%sTruthReco_2DHist%s.png\"%(savefolder,syst_set))\n",
    "\n",
    "    if use_fraction:\n",
    "        fractional_error = abs(truth - nn_reco)/ truth\n",
    "        plt.figure(figsize=(10,7))\n",
    "        plt.title(\"Fractional Error vs. Energy\")\n",
    "        plt.hist2d(truth, fractional_error,bins=60);\n",
    "        plt.xlabel(\"True Energy (GeV)\")\n",
    "        plt.ylabel(\"Fractional Error\")\n",
    "        #plt.ylim(0,0.5)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.set_ylabel('counts', rotation=90)\n",
    "        if save == True:\n",
    "            plt.savefig(\"%sTruthRecoFrac_2DHist%s.png\"%(savefolder,syst_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(network_history, save=save, savefolder=save_folder_name)\n",
    "plot_2D_prediction(Y_test_energy, Y_test_predicted_energy, save=save, savefolder=save_folder_name)\n",
    "plot_distributions_CCNC(Y_test_all_labels,Y_test_energy, Y_test_predicted_energy, save=save,s avefolder=save_folder_name)\n",
    "plot_resolution_CCNC(Y_test_all_labels, Y_test_energy, Y_test_predicted_energy, save=save, savefolder=save_folder_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
