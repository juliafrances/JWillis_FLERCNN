{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Python script to do Robust Scaler on concatted files\n",
    "#  Takes in file name and path\n",
    "#  Outputs file with transformed obserable feature values\n",
    "#  Does not transform labels, leaves all labels\n",
    "#\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import h5py\n",
    "import time\n",
    "import os, sys\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'SomeRawMC/Level5p_IC86.2013_genie_nue.012640.100.cascade.lt60_vertexDC.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Files ###\n",
    "f = h5py.File(input_file, 'r')\n",
    "features_DC = f['features_DC'][:]\n",
    "features_IC = f['features_IC'][:]\n",
    "labels = f['labels'][:]\n",
    "reco = f['reco_labels'][:]\n",
    "f.close()\n",
    "del f\n",
    "\n",
    "assert features_DC.shape[0]==features_IC.shape[0], \"DC events not equal to IC events\"\n",
    "assert features_DC.shape[0]==labels.shape[0], \"DC events not equatl to IC events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 85649 samples, testing on 9517 samples\n"
     ]
    }
   ],
   "source": [
    "### Split into training and testing set ###\n",
    "num_train = int(features_DC.shape[0]*0.9) # 90% of data is training data (traininig+validation), 10% is test data\n",
    "print(\"training on {} samples, testing on {} samples\".format(num_train, features_DC.shape[0]-num_train))\n",
    "\n",
    "features_DC_train = features_DC[:num_train]\n",
    "features_IC_train = features_IC[:num_train]\n",
    "labels_train = labels[:num_train]\n",
    "reco_train = labels[:num_train]\n",
    "\n",
    "features_DC_test = features_DC[num_train:]\n",
    "features_IC_test = features_IC[num_train:]\n",
    "labels_test = labels[num_train:]\n",
    "reco_test = reco[num_train:]\n",
    "\n",
    "### Specify type for training and testing ##\n",
    "(X_train_DC_raw, X_train_IC_raw, Y_train_raw) = (features_DC_train, features_IC_train, labels_train)\n",
    "X_train_DC_raw = X_train_DC_raw.astype(\"float32\")\n",
    "X_train_IC_raw = X_train_IC_raw.astype(\"float32\")\n",
    "Y_train_raw = Y_train_raw.astype(\"float32\")\n",
    "reco_train_raw = reco_train.astype(\"float32\")\n",
    "\n",
    "(X_test_DC_raw, X_test_IC_raw, Y_test_raw) = (features_DC_test, features_IC_test, labels_test)\n",
    "X_test_DC_raw = X_test_DC_raw.astype(\"float32\")\n",
    "X_test_IC_raw = X_test_IC_raw.astype(\"float32\")\n",
    "Y_test_raw = Y_test_raw.astype(\"float32\")\n",
    "reco_test_raw = reco_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RobustScaler(a_list,q1,q3):\n",
    "    \"\"\"Robust Scaler calculation, uses the first quartile (q1) and third quartile (q3)\"\"\"\n",
    "    return [(x-q1)/(q3-q1) for x in a_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetQuartiles(a_list):\n",
    "    \"\"\"Masks zeros and finds the first and third quartiles\"\"\"\n",
    "    mask_zeros = numpy.logical_or(a_list>0,a_list<0)\n",
    "    a_list_nozero = a_list[mask_zeros]\n",
    "    q1, q3 = numpy.percentile(a_list_nozero,[25,75])\n",
    "\n",
    "    return q1, q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformData(full_data_set,preset=False):\n",
    "    \"\"\"\n",
    "    Performs Robust Scaler transformation\n",
    "    Inputs:\n",
    "        full_data_set = the expected 4D data (training input data)\n",
    "        preset = boolean that uses the precalculated quartiles (for numu track only) if True\n",
    "    Outputs:\n",
    "        transformed_data_set = same dimensions as input, but with Robuset transformed output\n",
    "    \"\"\"\n",
    "    q1_array = [0.7749999761581421, 9915.0, 9963.0, 9940.4541015625, 10.824397087097168]\n",
    "    q3_array = [1.475000023841858, 10533.0, 10703.0, 10608.0, 314.53932189941406]\n",
    "\n",
    "    for data_index in range(0,full_data_set.shape[3]):\n",
    "\n",
    "        data_list = full_data_set[:,:,:,data_index].flatten()\n",
    "\n",
    "        #Find quartiles on THIS file\n",
    "        if preset==False:\n",
    "            q1, q3 = GetQuartiles(data_list)\n",
    "            data_rb = RobustScaler(data_list,q1,q3)\n",
    "\n",
    "        # IF YOU WANT TO USE NUMU preset quartiles\n",
    "        if preset==True:\n",
    "            data_rb = RobustScaler(data_list,q1_array[data_index],q3_array[data_index])\n",
    "            print(\"THIS IS SPECIFIC TO DATA SET FOR 5 NUMU VARIABLES; set preset to false if this is not the case\")\n",
    "\n",
    "        data_rb = numpy.array(data_rb)\n",
    "        transformed_data_set = numpy.copy(full_data_set)\n",
    "\n",
    "    return transformed_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform input features into specified range ###\n",
    "X_train_DC_full = TransformData(X_train_DC_raw)\n",
    "X_test_DC_full  = TransformData(X_test_DC_raw)\n",
    "X_train_IC_full = TransformData(X_train_IC_raw)\n",
    "X_test_IC_full  = TransformData(X_test_IC_raw)\n",
    "print(\"Finished transforming the data using Robust Scaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = numpy.copy(Y_train_raw)\n",
    "Y_test       = numpy.copy(Y_test_raw)\n",
    "reco_train = numpy.copy(reco_train_raw)\n",
    "reco_test = numpy.copy(reco_test_raw)\n",
    "X_train_DC = numpy.copy(X_train_DC_full)\n",
    "X_test_DC           = numpy.copy(X_test_DC_full)\n",
    "X_train_IC = numpy.copy(X_train_IC_full)\n",
    "X_test_IC           = numpy.copy(X_test_IC_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save output to hdf5 file\n",
    "output_file = input_file[:-4] + \"transformed.hdf5\"\n",
    "f = h5py.File(output_file, \"w\")\n",
    "f.create_dataset(\"Y_train\", data=Y_train)\n",
    "f.create_dataset(\"Y_test\", data=Y_test)\n",
    "f.create_dataset(\"X_train_DC\", data=X_train_DC)\n",
    "f.create_dataset(\"X_test_DC\", data=X_test_DC)\n",
    "f.create_dataset(\"X_train_IC\", data=X_train_IC)\n",
    "f.create_dataset(\"X_test_IC\", data=X_test_IC)\n",
    "f.create_dataset(\"reco_train\",data=reco_train)\n",
    "f.create_dataset(\"reco_test\",data=reco_test)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
